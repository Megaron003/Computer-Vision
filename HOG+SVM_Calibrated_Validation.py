import cv2
import numpy as np
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, precision_recall_curve
from sklearn.preprocessing import StandardScaler
from sklearn.utils import resample
import os
import matplotlib.pyplot as plt
import seaborn as sns
from skimage import exposure
from skimage.feature import hog
import joblib
from tqdm import tqdm
import glob
from concurrent.futures import ThreadPoolExecutor, as_completed
from scipy import stats
import pandas as pd
from sklearn.calibration import calibration_curve
import warnings
warnings.filterwarnings('ignore')

class ScientificHOG_SVM_Validator:
    """Validador Cient√≠fico Completo para Modelo HOG+SVM"""
    
    def __init__(self, hog_parameters=None):
        if hog_parameters is None:
            self.hog_parameters = {
                'orientations': 9,
                'pixels_per_cell': (8, 8),
                'cells_per_block': (2, 2),
                'block_norm': 'L2-Hys',
                'transform_sqrt': True,
                'feature_vector': True
            }
        else:
            self.hog_parameters = hog_parameters
            
        self.svm = SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced')
        self.scaler = StandardScaler()
        self.results = {}
    
    # ==================== CARREGAMENTO DE DADOS ====================
    
    def load_all_images_from_folder(self, folder_path, label, resize_dim=(128, 128), max_workers=4):
        """Carrega todas as imagens com tracking de origem"""
        print(f"\nüìÅ Carregando {'POSITIVAS' if label == 1 else 'NEGATIVAS'} de: {folder_path}")
        
        image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.tif', '*.tiff', '*.bmp', '*.gif']
        image_files = []
        
        for ext in image_extensions:
            image_files.extend(glob.glob(os.path.join(folder_path, '**', ext), recursive=True))
            image_files.extend(glob.glob(os.path.join(folder_path, ext), recursive=False))
        
        image_files = list(set(image_files))
        print(f"üîç Encontradas {len(image_files)} arquivos de imagem")
        
        features_list = []
        file_origins = []
        failed_files = []
        
        def process_single_image(filepath):
            try:
                image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
                if image is None:
                    return None, filepath, None
                
                original_size = image.shape
                image = cv2.resize(image, resize_dim)
                image = exposure.equalize_adapthist(image)
                features = hog(image, **self.hog_parameters)
                
                return features, None, original_size
            except Exception as e:
                return None, filepath, None
        
        print("üîÑ Processando imagens...")
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_file = {executor.submit(process_single_image, filepath): filepath 
                            for filepath in image_files}
            
            for future in tqdm(as_completed(future_to_file), total=len(image_files), 
                             desc=f"Processing {'positive' if label == 1 else 'negative'}"):
                features, failed_file, orig_size = future.result()
                if features is not None:
                    features_list.append(features)
                    file_origins.append({
                        'original_size': orig_size,
                        'label': label
                    })
                elif failed_file:
                    failed_files.append(failed_file)
        
        print(f"‚úÖ Processadas com sucesso: {len(features_list)} imagens")
        if failed_files:
            print(f"‚ö†Ô∏è  {len(failed_files)} arquivos falharam")
        
        return features_list, len(features_list), file_origins
    
    def load_datasets_with_tracking(self, positive_path, negative_path):
        """Carrega datasets mantendo metadata de origem"""
        print("=" * 80)
        print("üß™ CARREGAMENTO CIENT√çFICO COM METADATA")
        print("=" * 80)
        
        positive_features, pos_count, pos_origins = self.load_all_images_from_folder(positive_path, 1)
        negative_features, neg_count, neg_origins = self.load_all_images_from_folder(negative_path, 0)
        
        X = np.array(positive_features + negative_features)
        y = np.array([1] * pos_count + [0] * neg_count)
        origins = pos_origins + neg_origins
        
        print(f"\nüìä ESTAT√çSTICAS DO DATASET:")
        print(f"   Positivas (C√¢ncer): {pos_count} imagens")
        print(f"   Negativas (Saud√°veis): {neg_count} imagens")
        print(f"   Total: {len(X)} imagens")
        print(f"   Propor√ß√£o: {pos_count}:{neg_count} ‚âà {pos_count/neg_count:.2f}:1")
        print(f"   Features HOG: {X.shape[1]}")
        
        # An√°lise de tamanhos originais
        sizes = [o['original_size'] for o in origins if o['original_size'] is not None]
        if sizes:
            avg_size = np.mean([s[0]*s[1] for s in sizes])
            print(f"   Tamanho m√©dio original: {int(avg_size):,} pixels")
        
        return X, y, origins
    
    # ==================== VALIDA√á√ÉO ESTAT√çSTICA ====================
    
    def statistical_validation(self, X, y, n_splits=5, n_bootstraps=1000):
        """Valida√ß√£o estat√≠stica robusta"""
        print("\n" + "=" * 80)
        print("üìä VALIDA√á√ÉO ESTAT√çSTICA ROBUSTA")
        print("=" * 80)
        
        # 1. Cross-Validation Estratificado
        print("\n1Ô∏è‚É£  CROSS-VALIDATION ESTRATIFICADA (5-fold):")
        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
        cv_scores = cross_val_score(self.svm, self.scaler.fit_transform(X), y, 
                                   cv=cv, scoring='accuracy', n_jobs=-1)
        
        print(f"   Scores: {cv_scores}")
        print(f"   M√©dia: {cv_scores.mean():.4f}")
        print(f"   Desvio Padr√£o: {cv_scores.std():.4f}")
        print(f"   Intervalo: [{cv_scores.min():.4f}, {cv_scores.max():.4f}]")
        
        # 2. Bootstrap Confidence Intervals
        print("\n2Ô∏è‚É£  INTERVALOS DE CONFIAN√áA (Bootstrap, n={n_bootstraps}):")
        
        bootstrapped_scores = []
        rng = np.random.RandomState(42)
        
        for i in tqdm(range(n_bootstraps), desc="Bootstrapping"):
            indices = rng.choice(len(X), len(X), replace=True)
            X_boot = X[indices]
            y_boot = y[indices]
            
            X_train, X_test, y_train, y_test = train_test_split(
                X_boot, y_boot, test_size=0.2, random_state=42, stratify=y_boot
            )
            
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            model = SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced')
            model.fit(X_train_scaled, y_train)
            score = model.score(X_test_scaled, y_test)
            bootstrapped_scores.append(score)
        
        bootstrapped_scores = np.array(bootstrapped_scores)
        ci_95 = np.percentile(bootstrapped_scores, [2.5, 97.5])
        ci_99 = np.percentile(bootstrapped_scores, [0.5, 99.5])
        
        print(f"   M√©dia Bootstrap: {bootstrapped_scores.mean():.4f}")
        print(f"   95% CI: [{ci_95[0]:.4f}, {ci_95[1]:.4f}]")
        print(f"   99% CI: [{ci_99[0]:.4f}, {ci_99[1]:.4f}]")
        
        # 3. Teste de Signific√¢ncia
        print("\n3Ô∏è‚É£  TESTE DE SIGNIFIC√ÇNCIA ESTAT√çSTICA:")
        
        # Teste t contra baseline (50%)
        t_stat, p_value = stats.ttest_1samp(bootstrapped_scores, 0.5)
        print(f"   Teste t contra baseline (50%):")
        print(f"   t-statistic = {t_stat:.4f}")
        print(f"   p-value = {p_value:.4e}")
        print(f"   Significativo (p < 0.05)? {'‚úÖ SIM' if p_value < 0.05 else '‚ùå N√ÉO'}")
        
        # Effect Size (Cohen's d)
        cohen_d = (bootstrapped_scores.mean() - 0.5) / bootstrapped_scores.std()
        print(f"   Effect Size (Cohen's d): {cohen_d:.4f}")
        print(f"   Interpreta√ß√£o: {'Grande' if cohen_d > 0.8 else 'M√©dio' if cohen_d > 0.5 else 'Pequeno'}")
        
        self.results['cv_scores'] = cv_scores
        self.results['bootstrapped_scores'] = bootstrapped_scores
        self.results['ci_95'] = ci_95
        self.results['ci_99'] = ci_99
        self.results['p_value'] = p_value
        self.results['cohen_d'] = cohen_d
        
        return bootstrapped_scores
    
    # ==================== AN√ÅLISE DE VI√âS ====================
    
    def bias_analysis(self, X, y, y_pred, y_pred_proba, origins=None):
        """An√°lise completa de vi√©s e equidade"""
        print("\n" + "=" * 80)
        print("‚öñÔ∏è  AN√ÅLISE DE VI√âS E EQUIDADE")
        print("=" * 80)
        
        # 1. Matriz de Confus√£o Detalhada
        cm = confusion_matrix(y, y_pred)
        tn, fp, fn, tp = cm.ravel()
        
        print("\n1Ô∏è‚É£  MATRIZ DE CONFUS√ÉO DETALHADA:")
        print(f"   Verdadeiros Negativos: {tn} ({tn/len(y)*100:.2f}%)")
        print(f"   Falsos Positivos: {fp} ({fp/len(y)*100:.2f}%)")
        print(f"   Falsos Negativos: {fn} ({fn/len(y)*100:.2f}%)")
        print(f"   Verdadeiros Positivos: {tp} ({tp/len(y)*100:.2f}%)")
        
        # 2. M√©tricas por Classe
        print("\n2Ô∏è‚É£  M√âTRICAS POR CLASSE:")
        
        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0  # Precis√£o positiva
        npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Precis√£o negativa
        
        print(f"   Sensibilidade (Recall Positivo): {sensitivity:.4f}")
        print(f"   Especificidade (Recall Negativo): {specificity:.4f}")
        print(f"   Valor Preditivo Positivo: {ppv:.4f}")
        print(f"   Valor Preditivo Negativo: {npv:.4f}")
        
        # 3. Vi√©s de Previs√£o
        print("\n3Ô∏è‚É£  AN√ÅLISE DE VI√âS DE PREVIS√ÉO:")
        
        # Calibration curve
        prob_true, prob_pred = calibration_curve(y, y_pred_proba, n_bins=10)
        
        plt.figure(figsize=(10, 8))
        
        # Subplot 1: Calibration Plot
        plt.subplot(2, 2, 1)
        plt.plot(prob_pred, prob_true, marker='o', linewidth=2)
        plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)
        plt.xlabel('Probabilidade M√©dia Predita')
        plt.ylabel('Fra√ß√£o de Positivos')
        plt.title('Curva de Calibra√ß√£o')
        plt.grid(True, alpha=0.3)
        
        # Subplot 2: Distribui√ß√£o de Probabilidades
        plt.subplot(2, 2, 2)
        plt.hist(y_pred_proba[y == 0], bins=30, alpha=0.7, label='Saud√°vel', density=True)
        plt.hist(y_pred_proba[y == 1], bins=30, alpha=0.7, label='C√¢ncer', density=True)
        plt.axvline(0.5, color='red', linestyle='--', alpha=0.7)
        plt.xlabel('Probabilidade de C√¢ncer')
        plt.ylabel('Densidade')
        plt.title('Distribui√ß√£o por Classe')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Subplot 3: ROC Curve
        plt.subplot(2, 2, 3)
        fpr, tpr, _ = roc_curve(y, y_pred_proba)
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')
        plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Curva ROC')
        plt.legend(loc='lower right')
        plt.grid(True, alpha=0.3)
        
        # Subplot 4: Precision-Recall Curve
        plt.subplot(2, 2, 4)
        precision, recall, _ = precision_recall_curve(y, y_pred_proba)
        pr_auc = auc(recall, precision)
        plt.plot(recall, precision, label=f'AUC = {pr_auc:.4f}')
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Curva Precision-Recall')
        plt.legend(loc='lower left')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        print(f"\n   AUC-ROC: {roc_auc:.4f}")
        print(f"   AUC-PR: {pr_auc:.4f}")
        
        # 4. An√°lise de Limiar √ìtimo
        print("\n4Ô∏è‚É£  AN√ÅLISE DE LIMIAR √ìTIMO:")
        
        # Encontra limiar que maximiza F1-score
        thresholds = np.arange(0.1, 0.9, 0.05)
        f1_scores = []
        
        for thresh in thresholds:
            y_pred_thresh = (y_pred_proba >= thresh).astype(int)
            tp = np.sum((y_pred_thresh == 1) & (y == 1))
            fp = np.sum((y_pred_thresh == 1) & (y == 0))
            fn = np.sum((y_pred_thresh == 0) & (y == 1))
            
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
            f1_scores.append(f1)
        
        optimal_idx = np.argmax(f1_scores)
        optimal_thresh = thresholds[optimal_idx]
        
        print(f"   Limiar padr√£o: 0.5")
        print(f"   Limiar √≥timo (max F1): {optimal_thresh:.2f}")
        print(f"   F1-score no limiar √≥timo: {f1_scores[optimal_idx]:.4f}")
        
        self.results['sensitivity'] = sensitivity
        self.results['specificity'] = specificity
        self.results['roc_auc'] = roc_auc
        self.results['pr_auc'] = pr_auc
        self.results['optimal_threshold'] = optimal_thresh
        
        return optimal_thresh
    
    # ==================== VALIDA√á√ÉO DO MODELO ====================
    
    def comprehensive_model_validation(self, X, y, test_size=0.2):
        """Valida√ß√£o completa do modelo"""
        print("\n" + "=" * 80)
        print("üß¨ VALIDA√á√ÉO COMPLETA DO MODELO HOG+SVM")
        print("=" * 80)
        
        # 1. Split dos dados
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        # 2. Normaliza√ß√£o
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # 3. Treinamento
        print("\nü§ñ TREINANDO MODELO FINAL...")
        self.svm.fit(X_train_scaled, y_train)
        
        # 4. Predi√ß√µes
        y_pred = self.svm.predict(X_test_scaled)
        y_pred_proba = self.svm.predict_proba(X_test_scaled)[:, 1]
        
        # 5. M√©tricas
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nüìä DESEMPENHO NO CONJUNTO DE TESTE:")
        print(f"   Acur√°cia: {accuracy:.4f}")
        print(f"   Tamanho do teste: {len(y_test)} amostras")
        print(f"   Propor√ß√£o: {np.sum(y_test)} positivas / {len(y_test)-np.sum(y_test)} negativas")
        
        # 6. Relat√≥rio detalhado
        print("\nüìã RELAT√ìRIO DE CLASSIFICA√á√ÉO:")
        print(classification_report(y_test, y_pred, target_names=['Saud√°vel', 'C√¢ncer'], digits=4))
        
        self.results['X_test'] = X_test
        self.results['y_test'] = y_test
        self.results['y_pred'] = y_pred
        self.results['y_pred_proba'] = y_pred_proba
        self.results['accuracy'] = accuracy
        
        return X_test_scaled, y_test, y_pred, y_pred_proba
    
    # ==================== RELAT√ìRIO CIENT√çFICO ====================
    
    def generate_scientific_report(self):
        """Gera relat√≥rio cient√≠fico completo"""
        print("\n" + "=" * 80)
        print("üìÑ RELAT√ìRIO CIENT√çFICO COMPLETO")
        print("=" * 80)
        
        report = {
            'model': 'HOG + SVM Linear',
            'hog_parameters': self.hog_parameters,
            'dataset_size': len(self.results.get('X_test', [])) * 5,  # Estimativa
            'statistical_validation': {},
            'performance_metrics': {},
            'bias_analysis': {},
            'conclusions': []
        }
        
        # Estat√≠sticas
        if 'cv_scores' in self.results:
            report['statistical_validation']['cross_validation'] = {
                'mean_accuracy': float(self.results['cv_scores'].mean()),
                'std_accuracy': float(self.results['cv_scores'].std()),
                'ci_95_cv': [float(self.results['cv_scores'].mean() - 1.96*self.results['cv_scores'].std()),
                            float(self.results['cv_scores'].mean() + 1.96*self.results['cv_scores'].std())]
            }
        
        if 'bootstrapped_scores' in self.results:
            report['statistical_validation']['bootstrap'] = {
                'mean_accuracy': float(self.results['bootstrapped_scores'].mean()),
                'ci_95': [float(self.results['ci_95'][0]), float(self.results['ci_95'][1])],
                'ci_99': [float(self.results['ci_99'][0]), float(self.results['ci_99'][1])],
                'p_value': float(self.results['p_value']),
                'cohen_d': float(self.results['cohen_d'])
            }
        
        # M√©tricas de performance
        if 'accuracy' in self.results:
            report['performance_metrics'] = {
                'accuracy': float(self.results['accuracy']),
                'sensitivity': float(self.results.get('sensitivity', 0)),
                'specificity': float(self.results.get('specificity', 0)),
                'roc_auc': float(self.results.get('roc_auc', 0)),
                'pr_auc': float(self.results.get('pr_auc', 0))
            }
        
        # Conclus√µes
        if self.results.get('p_value', 1) < 0.05:
            report['conclusions'].append("‚úÖ O modelo √© estatisticamente significativo (p < 0.05)")
        
        if self.results.get('roc_auc', 0) > 0.95:
            report['conclusions'].append("‚úÖ Excelente capacidade discriminativa (AUC > 0.95)")
        
        if self.results.get('cohen_d', 0) > 0.8:
            report['conclusions'].append("‚úÖ Grande tamanho de efeito (Cohen's d > 0.8)")
        
        if abs(self.results.get('sensitivity', 0) - self.results.get('specificity', 0)) < 0.1:
            report['conclusions'].append("‚úÖ Balanceado entre sensibilidade e especificidade")
        else:
            report['conclusions'].append("‚ö†Ô∏è  Poss√≠vel vi√©s - verificar diferen√ßa sensibilidade/especificidade")
        
        # Imprime relat√≥rio
        print("\nüìà RESUMO ESTAT√çSTICO:")
        print(f"   Acur√°cia m√©dia: {report['performance_metrics'].get('accuracy', 0):.4f}")
        print(f"   AUC-ROC: {report['performance_metrics'].get('roc_auc', 0):.4f}")
        print(f"   Sensibilidade: {report['performance_metrics'].get('sensitivity', 0):.4f}")
        print(f"   Especificidade: {report['performance_metrics'].get('specificity', 0):.4f}")
        
        print("\nüìä VALIDA√á√ÉO ESTAT√çSTICA:")
        print(f"   p-value: {report['statistical_validation'].get('bootstrap', {}).get('p_value', 0):.4e}")
        print(f"   95% CI: {report['statistical_validation'].get('bootstrap', {}).get('ci_95', [0, 0])}")
        print(f"   Cohen's d: {report['statistical_validation'].get('bootstrap', {}).get('cohen_d', 0):.4f}")
        
        print("\nüéØ CONCLUS√ïES:")
        for conclusion in report['conclusions']:
            print(f"   {conclusion}")
        
        print("\n" + "=" * 80)
        print("üß™ VALIDA√á√ÉO CIENT√çFICA CONCLU√çDA")
        print("=" * 80)
        
        return report
    
    # ==================== FUN√á√ÉO PRINCIPAL ====================
    
    def run_complete_validation(self, positive_path, negative_path):
        """Executa valida√ß√£o cient√≠fica completa"""
        try:
            # 1. Carregar dados
            print("üöÄ INICIANDO VALIDA√á√ÉO CIENT√çFICA COMPLETA")
            X, y, origins = self.load_datasets_with_tracking(positive_path, negative_path)
            
            # 2. Valida√ß√£o estat√≠stica
            self.statistical_validation(X, y)
            
            # 3. Treinamento e valida√ß√£o do modelo
            X_test_scaled, y_test, y_pred, y_pred_proba = self.comprehensive_model_validation(X, y)
            
            # 4. An√°lise de vi√©s
            self.bias_analysis(X_test_scaled, y_test, y_pred, y_pred_proba, origins)
            
            # 5. Relat√≥rio final
            report = self.generate_scientific_report()
            
            # 6. Salvar resultados
            self.save_validation_results(report)
            
            return report
            
        except Exception as e:
            print(f"\n‚ùå ERRO NA VALIDA√á√ÉO: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def save_validation_results(self, report):
        """Salva resultados da valida√ß√£o"""
        import json
        import datetime
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"hog_svm_validation_report_{timestamp}.json"
        
        with open(filename, 'w') as f:
            json.dump(report, f, indent=4, default=str)
        
        print(f"\nüíæ Relat√≥rio salvo como: {filename}")
        
        # Salva tamb√©m o modelo
        model_data = {
            'svm': self.svm,
            'scaler': self.scaler,
            'hog_parameters': self.hog_parameters,
            'validation_report': report
        }
        joblib.dump(model_data, f"hog_svm_validated_model_{timestamp}.pkl")
        print(f"üíæ Modelo validado salvo como: hog_svm_validated_model_{timestamp}.pkl")

# ==================== EXECU√á√ÉO ====================

if __name__ == "__main__":
    # Configura√ß√µes
    POSITIVE_PATH = "C:/Users/GuilhermeBragadoVale/Desktop/Computer_Vision_For_Health/Cerebral_Cancer/Dataset/Cancer_brain"
    NEGATIVE_PATH = "C:/Users/GuilhermeBragadoVale/Desktop/Computer_Vision_For_Health/Cerebral_Cancer/Dataset/Healthy_brain"
    
    # Executar valida√ß√£o completa
    validator = ScientificHOG_SVM_Validator()
    report = validator.run_complete_validation(POSITIVE_PATH, NEGATIVE_PATH)
    
    # Resultado final
    if report:
        print("\n" + "=" * 80)
        print("üéâ VALIDA√á√ÉO CIENT√çFICA CONCLU√çDA COM SUCESSO!")
        print("=" * 80)
        print("\nEste modelo est√° pronto para publica√ß√£o cient√≠fica com:")
        print("‚úÖ Valida√ß√£o estat√≠stica robusta")
        print("‚úÖ An√°lise de vi√©s completa")
        print("‚úÖ Intervalos de confian√ßa")
        print("‚úÖ Testes de signific√¢ncia")
        print("‚úÖ M√©tricas de equidade")